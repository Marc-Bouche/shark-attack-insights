{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def3b206-030f-419c-a495-4d7805487d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd in /opt/anaconda3/lib/python3.12/site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "!pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc254da6-d774-4a75-8f66-074529bfd850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t2/40gs14tj4lg2536r26vzcyv40000gn/T/ipykernel_76849/1716933119.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  s_d[\"Type\"].replace(\" Provoked\",\"Provoked\",inplace=True)\n",
      "/var/folders/t2/40gs14tj4lg2536r26vzcyv40000gn/T/ipykernel_76849/1716933119.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filter_fatal[\"Injury\"] = filter_fatal[\"Injury\"].apply(lambda x: \"fatal\")\n",
      "/var/folders/t2/40gs14tj4lg2536r26vzcyv40000gn/T/ipykernel_76849/1716933119.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filter_non_fatal[\"Injury\"] = filter_non_fatal[\"Injury\"].apply(lambda x: \"non-fatal\")\n",
      "/var/folders/t2/40gs14tj4lg2536r26vzcyv40000gn/T/ipykernel_76849/1716933119.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filter_non_fatal2[\"Injury\"] = filter_non_fatal2[\"Injury\"].apply(lambda x: \"non-fatal\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Type</th>\n",
       "      <th>Provoked</th>\n",
       "      <th>Unprovoked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Injury</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fatal</th>\n",
       "      <td>17</td>\n",
       "      <td>1227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-fatal</th>\n",
       "      <td>620</td>\n",
       "      <td>3914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Type       Provoked  Unprovoked\n",
       "Injury                         \n",
       "fatal            17        1227\n",
       "non-fatal       620        3914"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hypothesis 1\n",
    "# Unprovoked shark attack incidents have a lower fatality rate than provoked incidents.\n",
    "\n",
    "# Loading Data\n",
    "shark_data = pd.read_excel('https://www.sharkattackfile.net/spreadsheets/GSAF5.xls')\n",
    "shark_data.head()\n",
    "s_d = shark_data.iloc[:,:14]\n",
    "\n",
    "# cleaning\n",
    "\n",
    "s_d = s_d.dropna(how='all')\n",
    "s_d = s_d.drop_duplicates()\n",
    "\n",
    "s_d[\"Injury\"].value_counts()\n",
    "shark_data[\"Injury\"].nunique()\n",
    "\n",
    "s_d[\"Type\"].replace(\" Provoked\",\"Provoked\",inplace=True)\n",
    "s_d[\"Injury\"] = s_d[\"Injury\"].apply(lambda x: x.lower() if type(x) == str else x) # making sure spelling is the same\n",
    "\n",
    "## Creating filters to filter for \"fatal\" and \"non-fatal\"\n",
    "\n",
    "condition1 = s_d[\"Injury\"].str.contains(\"fatal\") == True\n",
    "condition11 = s_d[\"Injury\"].str.contains(\"non-fatal\") != True\n",
    "condition12 = s_d[\"Injury\"].str.contains(\"not confirmed\") != True\n",
    "condition13 = s_d[\"Injury\"].str.contains(\"unconfirmed\") != True\n",
    "\n",
    "condition2 =  s_d[\"Injury\"].str.contains(\"fatal\") != True\n",
    "condition21 =  s_d[\"Injury\"].str.contains(\"unknown\") != True\n",
    "\n",
    "condition3 = s_d[\"Injury\"].str.contains(\"non-fatal\") == True\n",
    "\n",
    "### Creating filtered data frames\n",
    "\n",
    "filter_fatal = s_d[condition1 & condition11 & condition12 & condition13]\n",
    "filter_non_fatal = s_d[condition2 & condition21]\n",
    "filter_non_fatal2 = s_d[condition3]  \n",
    "\n",
    "s_d_unprovoked = s_d[s_d[\"Type\"] == \"Unprovoked\"]\n",
    "s_d_provoked = s_d[s_d[\"Type\"] == \"Provoked\"]\n",
    "\n",
    "#### Replace different values with coherent single values\n",
    "\n",
    "filter_fatal[\"Injury\"] = filter_fatal[\"Injury\"].apply(lambda x: \"fatal\")\n",
    "filter_non_fatal[\"Injury\"] = filter_non_fatal[\"Injury\"].apply(lambda x: \"non-fatal\")\n",
    "filter_non_fatal2[\"Injury\"] = filter_non_fatal2[\"Injury\"].apply(lambda x: \"non-fatal\")\n",
    "filter_non_fatal_concat = pd.concat([filter_non_fatal2, filter_non_fatal])\n",
    "\n",
    "##### Creating filtered data frames\n",
    "\n",
    "s_d_unprovoked_fatal = filter_fatal[filter_fatal[\"Type\"] == \"Unprovoked\"]\n",
    "s_d_unprovoked_non_fatal = filter_non_fatal_concat[filter_non_fatal_concat[\"Type\"] == \"Unprovoked\"]\n",
    "\n",
    "s_d_provoked_fatal = filter_fatal[filter_fatal[\"Type\"] == \"Provoked\"]\n",
    "s_d_provoked_non_fatal = filter_non_fatal_concat[filter_non_fatal_concat[\"Type\"] == \"Provoked\"]\n",
    "\n",
    "# Testing\n",
    "## Creating a final summarized data frame from the separate filterd dfs\n",
    "\n",
    "df_h1 = pd.concat([s_d_unprovoked_fatal, s_d_unprovoked_non_fatal, s_d_provoked_non_fatal, s_d_provoked_fatal])\n",
    "df_h1.groupby([\"Injury\",\"Type\"])[\"Injury\"].count()\n",
    "df_h1[\"count\"] = 1\n",
    "df_h1[\"count\"].value_counts()\n",
    "\n",
    "# Result\n",
    "\n",
    "df_h1.pivot_table(index = \"Injury\", columns = \"Type\", values = \"count\", aggfunc = \"sum\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2323352d-395c-4a21-8360-2bdd02c33aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Country</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>Invalid</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>Great White Shark</td>\n",
       "      <td>USA</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>Great White Shark</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>Great White Shark</td>\n",
       "      <td>SOUTH AFRICA</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Broadnose sevengill shark, 1.5 m</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Bronze whaler 1.5m</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Bronze whaler 2.5m</td>\n",
       "      <td>NEW ZEALAND</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Bronze whaler shark, 1.5 m</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>Great White Shark</td>\n",
       "      <td>PAPUA NEW GUINEA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>805 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Species           Country  Count\n",
       "536                           Invalid               USA    685\n",
       "451                           Invalid         AUSTRALIA    335\n",
       "416                 Great White Shark               USA    229\n",
       "369                 Great White Shark         AUSTRALIA    184\n",
       "410                 Great White Shark      SOUTH AFRICA    171\n",
       "..                                ...               ...    ...\n",
       "280  Broadnose sevengill shark, 1.5 m         AUSTRALIA      1\n",
       "282                Bronze whaler 1.5m         AUSTRALIA      1\n",
       "283                Bronze whaler 2.5m       NEW ZEALAND      1\n",
       "286        Bronze whaler shark, 1.5 m         AUSTRALIA      1\n",
       "402                 Great White Shark  PAPUA NEW GUINEA      1\n",
       "\n",
       "[805 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hypothesis 2 \n",
    "# Great White Sharks are most likely to attack in the USA. \n",
    "\n",
    "# Loading Data\n",
    "import pandas as pd\n",
    "shark_data =pd.read_excel('https://www.sharkattackfile.net/spreadsheets/GSAF5.xls')\n",
    "shark_data.head()\n",
    "# Cleaning: Species\n",
    "shark_data.rename(columns={\"Species \": \"Species\"}, inplace=True) #rename species column\n",
    "#shark_data[\"Species\"].drop(shark_data[(shark_data == 0).any(axis=1)].index, inplace=True) # removes 0 value\n",
    "#shark_data.dropna(subset=['Species'], inplace=True) #removes NaN\n",
    "shark_data[\"Species\"] = shark_data[\"Species\"].apply(lambda x: \"Tiger Shark\" if \"tiger\" in str(x).lower() else x)\n",
    "shark_data[\"Species\"] = shark_data[\"Species\"].apply(lambda x: \"Bull Shark\" if \"bull\" in str(x).lower() else x)\n",
    "shark_data[\"Species\"] = shark_data[\"Species\"].apply(lambda x: \"Blue Pointer\" if \"blue\" in str(x).lower() else x)\n",
    "shark_data[\"Species\"] = shark_data[\"Species\"].apply(lambda x: \"Great White Shark\" if \"white\" in str(x).lower() else x)\n",
    "shark_data[\"Species\"] = shark_data[\"Species\"].apply(lambda x: \"Hammerhead Shark\" if \"hammer\" in str(x).lower() else x)\n",
    "shark_data[\"Species\"] = shark_data[\"Species\"].apply(lambda x: \"Catshark\" if \"cat\" in str(x).lower() else x)\n",
    "shark_data[\"Species\"] = shark_data[\"Species\"].apply(lambda x: \"Hammerhead Shark\" if \"hammer\" in str(x).lower() else x)\n",
    "shark_data[\"Species\"] = shark_data[\"Species\"].apply(lambda x: \"Brown Shark\" if \"brown\" in str(x).lower() else x)\n",
    "shark_data[\"Species\"] = shark_data[\"Species\"].apply(lambda x: \"Blacktip\" if \"black\" in str(x).lower() else x)\n",
    "shark_data[\"Species\"] = shark_data[\"Species\"].apply(lambda x: \"Invalid\" if \"NaN\" in str(x).lower() else x)\n",
    "shark_data[\"Species\"] = shark_data[\"Species\"].apply(lambda x: \"Invalid\" if \"questionable\" in str(x).lower() else x)\n",
    "shark_data[\"Species\"] = shark_data[\"Species\"].apply(lambda x: \"Invalid\" if \"involvement\" in str(x).lower() else x)\n",
    "shark_data[\"Species\"] = shark_data[\"Species\"].apply(lambda x: \"Invalid\" if \"'\" in str(x).lower() else x)\n",
    "shark_data[\"Species\"] = shark_data[\"Species\"].apply(lambda x: \"Invalid\" if \"''\" in str(x).lower() else x)\n",
    "shark_data[\"Species\"] = shark_data[\"Species\"].apply(lambda x: \"Invalid\" if \"[]\" in str(x).lower() else x)\n",
    "# Cleaning: Country\n",
    "def clean_country(country):\n",
    "    # Handle NaN values\n",
    "    if pd.isna(country):\n",
    "        return 'UNSPECIFIED COUNTRY'\n",
    "    # Remove question marks and strip whitespace\n",
    "    country = country.replace('?', '').strip()\n",
    "    # Handle cases where multiple countries are listed\n",
    "    country = country.replace('IRAN / IRAQ', 'IRAN') \\\n",
    "                     .replace('SOLOMON ISLANDS / VANUATU', 'SOLOMON ISLANDS') \\\n",
    "                     .replace('EQUATORIAL GUINEA / CAMEROON', 'CAMEROON') \\\n",
    "                     .replace('CEYLON (SRI LANKA)', 'SRI LANKA') \\\n",
    "                     .replace('EGYPT / ISRAEL', 'EGYPT') \\\n",
    "                     .replace('ITALY / CROATIA', 'ITALY') \\\n",
    "                     .replace('BETWEEN PORTUGAL & INDIA', 'UNSPECIFIED COUNTRY') \\\n",
    "                     .replace('DIEGO GARCIA', 'UNSPECIFIED COUNTRY')\n",
    "    # Replace \"/\" with \"and\" in specific countries\n",
    "    country = country.replace('ANDAMAN / NICOBAR ISLANDS', 'ANDAMAN AND NICOBAR ISLANDS') \\\n",
    "                     .replace('ST KITTS / NEVIS', 'ST KITTS AND NEVIS')\n",
    "    # Mapping replacements for specific island entries\n",
    "    replacements = {\n",
    "        'UNITED ARAB EMIRATES (UAE)': 'UNITED ARAB EMIRATES',\n",
    "        'NEW GUINEA / PAPUA NEW GUINEA': 'PAPUA NEW GUINEA',\n",
    "        'SOLOMON ISLANDS / VANUATU': 'SOLOMON ISLANDS',\n",
    "        'MALDIVE ISLANDS': 'MALDIVES',\n",
    "        'ST. MAARTIN': 'ST. MARTIN',  # Correct spelling\n",
    "        'KOREA': 'SOUTH KOREA'        # Replace KOREA with SOUTH KOREA\n",
    "    }\n",
    "    # Apply replacements\n",
    "    for key, value in replacements.items():\n",
    "        if country == key:\n",
    "            country = value\n",
    "    # Assign 'UNSPECIFIED COUNTRY' to values containing sea/ocean-related terms\n",
    "    sea_terms = ['sea', 'SEA', 'OCEAN', 'ocean', 'Ocean', 'Sea', 'BAY OF BENGAL', 'AFRICA']\n",
    "    for term in sea_terms:\n",
    "        if term in country:\n",
    "            return 'UNSPECIFIED COUNTRY'\n",
    "    # Remove invalid countries or regions\n",
    "    invalid_countries = ['Diego Garcia', 'GULF OF ADEN', 'THE BALKANS', 'BRITISH ISLES', 'PERSIAN GULF', 'JOHNSTON ISLAND',\n",
    "                         'JAVA', 'ROTAN', 'SAN DOMINGO', 'ST. MARTIN', 'NEVIS', 'GRAND CAYMAN', 'NETHERLANDS ANTILLES',\n",
    "                         'NORTHERN MARIANA ISLANDS', 'ASIA']\n",
    "    if country in invalid_countries:\n",
    "        return 'UNSPECIFIED COUNTRY'\n",
    "    # Convert all to uppercase\n",
    "    country = country.upper()\n",
    "# Group by 'Species' and 'Country', and count the occurrences\n",
    "shark_attacks_count = shark_data.groupby(['Species', 'Country']).size().reset_index(name='Count')\n",
    "# Sort the DataFrame by the Count in descending order\n",
    "shark_attacks_count = shark_attacks_count.sort_values(by='Count', ascending=False)\n",
    "shark_attacks_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf189f1b-4c50-4291-b541-fd215518fc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Number of Attacks\n",
      "Sex                       \n",
      "Female                 744\n",
      "Invalid                580\n",
      "Male                  5474\n"
     ]
    }
   ],
   "source": [
    "## Hypothesis 4 \n",
    "## Males have higher chances than females of being attacked by a shark.  \n",
    "\n",
    "# Loading Data\n",
    "import pandas as pd\n",
    "shark_data =pd.read_excel('https://www.sharkattackfile.net/spreadsheets/GSAF5.xls')\n",
    "shark_data.head()\n",
    "\n",
    "# Cleaning: Sex\n",
    "shark_data[\"Sex\"] = shark_data[\"Sex\"].apply(lambda x: \"Male\" if \"m\" in str(x).lower() else x)\n",
    "shark_data[\"Sex\"] = shark_data[\"Sex\"].apply(lambda x: \"Female\" if \"f\" in str(x).lower() else x)\n",
    "shark_data[\"Sex\"] = shark_data[\"Sex\"].apply(lambda x: \"Invalid\" if \"nan\" in str(x).lower() else x)\n",
    "shark_data[\"Sex\"] = shark_data[\"Sex\"].apply(lambda x: \"Invalid\" if \"n\" in str(x).lower() else x)\n",
    "shark_data[\"Sex\"] = shark_data[\"Sex\"].apply(lambda x: \"Invalid\" if \"lli\" in str(x).lower() else x)\n",
    "shark_data[\"Sex\"] = shark_data[\"Sex\"].apply(lambda x: \"Invalid\" if \"M x 2\" in str(x).lower() else x)\n",
    "shark_data[\"Sex\"] = shark_data[\"Sex\"].apply(lambda x: \"Invalid\" if \".\" in str(x).lower() else x)\n",
    "\n",
    "# Create a pivot table with 'Sex ' as the index and count the number of shark attacks for each category\n",
    "pivot_table = pd.pivot_table(shark_data,index='Sex',values='Case Number', aggfunc='count')\n",
    "pivot_table.columns = ['Number of Attacks']\n",
    "print(pivot_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
